{"mode":"block","xmlText":"<xml xmlns=\"https://developers.google.com/blockly/xml\"><block type=\"ai_event_forever\" id=\"476+L,b7`_XJF_cC5H%/\" x=\"-812\" y=\"-737\"><statement name=\"ONSTART\"><block type=\"ai_display_turnon_camera\" id=\"!pp~Kq8[s+v/@th8]WIz\"><field name=\"camera\">environment</field><next><block type=\"ai_ml_image_classify_event\" id=\"jhV.+V?Km8Ag^pSq=MF5\"><field name=\"mirror\">TRUE</field><field name=\"model\">78b6c917-67da-4313-bf1e-1c650b74d505</field><statement name=\"event_handler\"><block type=\"ai_display_background\" id=\"A8Gx(cpKRjOJH?l/*3,x\"><value name=\"COLOR\"><shadow type=\"colour_picker\" id=\"]BlZ)Ld?(p,Vs5ji*Y^W\"><field name=\"COLOUR\">#ffffff</field></shadow></value><next><block type=\"ai_display_text\" id=\"Yi?lEaI7q)=UaQwNY7EF\"><value name=\"TEXT\"><shadow type=\"text\" id=\"LbBaYKu95wN4j1e?eYF7\"><field name=\"TEXT\">Hello</field></shadow><block type=\"ai_ml_classify_result\" id=\"f?Mt_9h~n9A[|AH2n5jN\"><field name=\"type\">label</field><value name=\"order\"><shadow type=\"math_number\" id=\"|7SyM?K6Q.r_eSM:w_*K\"><field name=\"NUM\">1</field></shadow></value></block></value><value name=\"X\"><shadow type=\"math_number\" id=\"l*,8v6QBou!eXpAhA5Ya\"><field name=\"NUM\">100</field></shadow></value><value name=\"Y\"><shadow type=\"math_number\" id=\"XhA_BYbsV,;m=N%2ntkc\"><field name=\"NUM\">250</field></shadow></value><next><block type=\"controls_if\" id=\"6b92YoT4(i8*(|z4Rh#q\"><value name=\"IF0\"><block type=\"ai_ml_classify_result_compare_label\" id=\"02B^;voLt]I$@=r2KwJ-\"><value name=\"index\"><shadow type=\"math_number\" id=\"?aQK?B71/sjd*;?LOM1W\"><field name=\"NUM\">1</field></shadow></value><value name=\"label\"><shadow type=\"text\" id=\"[l^KrkE(%}|5cqsMocVA\"><field name=\"TEXT\">Nhi</field></shadow></value></block></value><statement name=\"DO0\"><block type=\"ai_device_send_string\" id=\"ZIyqd2D!1v|5t9x3`I|w\"><value name=\"message\"><shadow type=\"text\" id=\")6^Q{k;NX.OgY%T?nztu\"><field name=\"TEXT\">A</field></shadow></value></block></statement><next><block type=\"controls_if\" id=\"D]$YQ;(DUr9GzX:z(FS+\"><value name=\"IF0\"><block type=\"ai_ml_classify_result_compare_label\" id=\"S-QAk[TIsVXfL_L][=lF\"><value name=\"index\"><shadow type=\"math_number\" id=\"Zc{mShT|d:+H;C~f0Xb]\"><field name=\"NUM\">1</field></shadow></value><value name=\"label\"><shadow type=\"text\" id=\"=w1/qtk6q_Lf-p8m8r#7\"><field name=\"TEXT\">Others</field></shadow></value></block></value><statement name=\"DO0\"><block type=\"ai_device_send_string\" id=\"~E`NeJWW~Rb?/m+!wQIz\"><value name=\"message\"><shadow type=\"text\" id=\"c#;BXEATh}dS.S%j*WFo\"><field name=\"TEXT\">C</field></shadow></value></block></statement></block></next></block></next></block></next></block></statement></block></next></block></statement><statement name=\"FOREVER\"><block type=\"ai_display_image_camera\" id=\"C_fw`=[TvwWz@yP`qFD-\"><field name=\"MIRROR\">TRUE</field><value name=\"X\"><shadow type=\"math_number\" id=\"]ssyQee~kb.=|boK=Xq2\"><field name=\"NUM\">0</field></shadow></value><value name=\"Y\"><shadow type=\"math_number\" id=\"%9#3_Yl+T|Pt;wTRxo3y\"><field name=\"NUM\">0</field></shadow></value><value name=\"WIDTH\"><shadow type=\"math_number\" id=\"EabHBbj.IG5.qhI`sNa[\"><field name=\"NUM\">320</field></shadow></value><value name=\"HEIGHT\"><shadow type=\"math_number\" id=\"kZHR15K+^JWLtJ=n1hL{\"><field name=\"NUM\">240</field></shadow></value></block></statement></block></xml>","javascript":"function loadAIModel(fromLocal, URI, modelType) { // modelType = 0:image, 1:audio, 2:pose\n  if (fromLocal) {\n    if (modelType == 0) {  // video classification model\n      const projects = JSON.parse(window.localStorage.getItem(\"ohstemai_projects\"));\n      let project;\n      if (projects && projects.data && Boolean(projects.data)) {\n        project = projects.data[URI];\n      }\n\n      parent.tf.loadLayersModel(\"indexeddb://\" + project.id).then((layersModel) => {\n        tmModel = new parent.tm.CustomMobileNet(layersModel, project.metadata);\n      }).catch((err) => console.log(err));\n    } else if (modelType == 1) {  // sound classification model\n      // Load the model first\n      const baseRecognizer = parent.spc.create(\"BROWSER_FFT\");\n      baseRecognizer\n        .ensureModelLoaded()\n        .then(() => {\n          tmModelAudio = baseRecognizer.createTransfer(URI);\n          console.log(`@tensorflow/speech-commands Transfer recognizer created (version ${parent.spc.version})`);\n          console.log(\"loading model\", URI);\n          return tmModelAudio.load();\n      })\n      .then(() => tmModelAudio.ensureModelLoaded())\n      .then(() => {\n        console.log(\"loaded model\", tmModelAudio);\n        // Start classifying\n        classifySound(true);\n      })\n      .catch((err) => console.log(err));\n    }\n  } else {\n    if (modelType == 0) {\n      imageClassifier = ml5.imageClassifier(URI + \"model.json\");\n    } else {\n      soundClassifier = ml5.soundClassifier(URI + \"model.json\");\n    }\n  }\n}\n\nfunction classifyVideo(mirror, useLocalModel, continuous) {\n  if (!parent || Boolean(parent.isStopCode)) {return;}\n\n  let videoImage = mirror?ml5.flipImage(videoCamera):videoCamera;\n  if (useLocalModel) {\n    if (tmModel) {\n      tmModel.predict(mirror?videoImage.canvas:videoImage.elt).then((predictions) => {\n        classifyVideoGotResult(undefined, predictions.sort((a, b) => b.probability - a.probability).map((p) => ({ label: p.className, confidence: p.probability })));\n        if (continuous) {\n          classifyVideo(mirror, useLocalModel, continuous);\n        }\n      }).catch((err) => classifyVideoGotResult(err, undefined));\n    } else {\n      setTimeout(classifyVideo, 500, mirror, useLocalModel, continuous);\n    }\n  } else {\n    imageClassifier.classify(videoImage, (err, results) => {\n      if (err) {\n        classifyVideoGotResult(err, undefined);\n      } else {\n        classifyVideoGotResult(undefined, results);\n        if (continuous) {\n          //classify again!\n          classifyVideo(mirror, useLocalModel, continuous);\n        }\n      }\n    });\n  }\n\n  if (mirror) videoImage.remove();\n}\n\nfunction classifyVideoGotResult(error, classifyResults) {\n  if (error) {\n    console.error(error);\n    return;\n  }\n\n  // handle result here\n  background('#ffffff');\n  text((classifyResults[0].label) , 100, 250);\n  if (classifyResults[0].label == 'Nhi') {\n    parent.commandUtils.sendTerminalData('A');\n  }\n  if (classifyResults[0].label == 'Others') {\n    parent.commandUtils.sendTerminalData('C');\n  }\n\n}\n\nfunction sleep(s) {\n  ms = s * 1000\n  return new Promise(resolve => setTimeout(resolve, ms));\n}\n\n\nlet videoCamera;\nlet imageClassifier;\n\nlet soundClassifier;\n\nlet tmModel;\n\nfunction preload() {\n  loadAIModel(true, \"78b6c917-67da-4313-bf1e-1c650b74d505\", 0);\n}\n\nfunction setup() {\n  createCanvas(window.parent.document.getElementById('js-runner-container').offsetWidth-50, window.parent.document.getElementById('js-runner-container').offsetHeight-50);\n    videoCamera = createCapture({audio: false, video: {facingMode: \"environment\"}});\n  videoCamera.size(width, height);\n  videoCamera.hide();\n  classifyVideo(true, true, true);\n\n}\n\nfunction draw() {\n  let flippedImage = ml5.flipImage(videoCamera);\n  image(flippedImage, 0, 0, 320, 240);\n  flippedImage.remove();\n\n}\n","name":"face","extensions":[],"device":"ai"}